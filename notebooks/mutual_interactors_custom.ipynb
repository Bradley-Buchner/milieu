{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "96d6acc3170d41c8bc95dd97e480ddba": {
          "model_module": "cytoscape-jupyter-widget",
          "model_name": "CytoscapeModel",
          "model_module_version": "^0.1.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "cytoscape-jupyter-widget",
            "_model_module_version": "^0.1.0",
            "_model_name": "CytoscapeModel",
            "_view_count": null,
            "_view_module": "cytoscape-jupyter-widget",
            "_view_module_version": "^0.1.0",
            "_view_name": "CytoscapeView",
            "background": "#FFFFFF",
            "data": {
              "elements": {
                "nodes": [
                  {
                    "data": {
                      "role": "seed",
                      "id": "925",
                      "entrez": "1280",
                      "genbank": "COL2A1",
                      "normalized_milieu_weight": 1
                    }
                  },
                  {
                    "data": {
                      "role": "seed",
                      "id": "2271",
                      "entrez": "3265",
                      "genbank": "HRAS",
                      "normalized_milieu_weight": 1
                    }
                  },
                  {
                    "data": {
                      "role": "seed",
                      "id": "5941",
                      "entrez": "8642",
                      "genbank": "DCHS1",
                      "normalized_milieu_weight": 1
                    }
                  },
                  {
                    "data": {
                      "role": "seed",
                      "id": "4662",
                      "entrez": "6628",
                      "genbank": "SNRPB",
                      "normalized_milieu_weight": 1
                    }
                  },
                  {
                    "data": {
                      "role": "seed",
                      "id": "3435",
                      "entrez": "5000",
                      "genbank": "ORC4",
                      "normalized_milieu_weight": 1
                    }
                  },
                  {
                    "data": {
                      "role": "seed",
                      "id": "5774",
                      "entrez": "8425",
                      "genbank": "LTBP4",
                      "normalized_milieu_weight": 1
                    }
                  },
                  {
                    "data": {
                      "role": "seed",
                      "id": "1663",
                      "entrez": "2317",
                      "genbank": "FLNB",
                      "normalized_milieu_weight": 1
                    }
                  },
                  {
                    "data": {
                      "role": "seed",
                      "id": "3734",
                      "entrez": "5396",
                      "genbank": "PRRX1",
                      "normalized_milieu_weight": 1
                    }
                  },
                  {
                    "data": {
                      "role": "seed",
                      "id": "10732",
                      "entrez": "25782",
                      "genbank": "RAB3GAP2",
                      "normalized_milieu_weight": 1
                    }
                  },
                  {
                    "data": {
                      "role": "seed",
                      "id": "1623",
                      "entrez": "2263",
                      "genbank": "FGFR2",
                      "normalized_milieu_weight": 1
                    }
                  },
                  {
                    "data": {
                      "role": "seed",
                      "id": "10132",
                      "entrez": "23321",
                      "genbank": "TRIM2",
                      "normalized_milieu_weight": 1
                    }
                  },
                  {
                    "data": {
                      "role": "pred",
                      "id": "1624",
                      "entrez": "2264",
                      "genbank": "FGFR4",
                      "normalized_milieu_weight": 1
                    }
                  },
                  {
                    "data": {
                      "role": "pred",
                      "id": "1621",
                      "entrez": "2261",
                      "genbank": "FGFR3",
                      "normalized_milieu_weight": 1
                    }
                  },
                  {
                    "data": {
                      "role": "pred",
                      "id": "1620",
                      "entrez": "2260",
                      "genbank": "FGFR1",
                      "normalized_milieu_weight": 1
                    }
                  },
                  {
                    "data": {
                      "role": "pred",
                      "id": "926",
                      "entrez": "1281",
                      "genbank": "COL3A1",
                      "normalized_milieu_weight": 1
                    }
                  },
                  {
                    "data": {
                      "role": "pred",
                      "id": "936",
                      "entrez": "1291",
                      "genbank": "COL6A1",
                      "normalized_milieu_weight": 1
                    }
                  },
                  {
                    "data": {
                      "role": "mutual_interactor",
                      "id": "4698",
                      "entrez": "6667",
                      "genbank": "SP1",
                      "normalized_milieu_weight": 0.08941420912742615
                    }
                  },
                  {
                    "data": {
                      "role": "mutual_interactor",
                      "id": "1607",
                      "entrez": "2247",
                      "genbank": "FGF2",
                      "normalized_milieu_weight": 0.2813691794872284
                    }
                  },
                  {
                    "data": {
                      "role": "mutual_interactor",
                      "id": "1608",
                      "entrez": "2248",
                      "genbank": "FGF3",
                      "normalized_milieu_weight": 0.6101864576339722
                    }
                  },
                  {
                    "data": {
                      "role": "mutual_interactor",
                      "id": "4752",
                      "entrez": "6733",
                      "genbank": "SRPK2",
                      "normalized_milieu_weight": 0.07476813346147537
                    }
                  },
                  {
                    "data": {
                      "role": "mutual_interactor",
                      "id": "2422",
                      "entrez": "3500",
                      "genbank": "IGHG1",
                      "normalized_milieu_weight": 0.1838444620370865
                    }
                  },
                  {
                    "data": {
                      "role": "mutual_interactor",
                      "id": "14290",
                      "entrez": "55832",
                      "genbank": "CAND1",
                      "normalized_milieu_weight": 0.0672144964337349
                    }
                  },
                  {
                    "data": {
                      "role": "mutual_interactor",
                      "id": "11026",
                      "entrez": "26270",
                      "genbank": "FBXO6",
                      "normalized_milieu_weight": 0.06804771721363068
                    }
                  },
                  {
                    "data": {
                      "role": "mutual_interactor",
                      "id": "6727",
                      "entrez": "9656",
                      "genbank": "MDC1",
                      "normalized_milieu_weight": 0.13044388592243195
                    }
                  },
                  {
                    "data": {
                      "role": "mutual_interactor",
                      "id": "3190",
                      "entrez": "4670",
                      "genbank": "HNRNPM",
                      "normalized_milieu_weight": 0.08951427042484283
                    }
                  }
                ],
                "edges": [
                  {
                    "data": {
                      "source": "5774",
                      "target": "2422",
                      "roles": "seed-mutual_interactor"
                    }
                  },
                  {
                    "data": {
                      "source": "5774",
                      "target": "11026",
                      "roles": "seed-mutual_interactor"
                    }
                  },
                  {
                    "data": {
                      "source": "4752",
                      "target": "1621",
                      "roles": "mutual_interactor-pred"
                    }
                  },
                  {
                    "data": {
                      "source": "4752",
                      "target": "4662",
                      "roles": "mutual_interactor-seed"
                    }
                  },
                  {
                    "data": {
                      "source": "11026",
                      "target": "936",
                      "roles": "mutual_interactor-pred"
                    }
                  },
                  {
                    "data": {
                      "source": "11026",
                      "target": "3435",
                      "roles": "mutual_interactor-seed"
                    }
                  },
                  {
                    "data": {
                      "source": "925",
                      "target": "936",
                      "roles": "seed-pred"
                    }
                  },
                  {
                    "data": {
                      "source": "925",
                      "target": "4698",
                      "roles": "seed-mutual_interactor"
                    }
                  },
                  {
                    "data": {
                      "source": "926",
                      "target": "4698",
                      "roles": "pred-mutual_interactor"
                    }
                  },
                  {
                    "data": {
                      "source": "926",
                      "target": "14290",
                      "roles": "pred-mutual_interactor"
                    }
                  },
                  {
                    "data": {
                      "source": "4662",
                      "target": "3190",
                      "roles": "seed-mutual_interactor"
                    }
                  },
                  {
                    "data": {
                      "source": "4662",
                      "target": "6727",
                      "roles": "seed-mutual_interactor"
                    }
                  },
                  {
                    "data": {
                      "source": "4662",
                      "target": "14290",
                      "roles": "seed-mutual_interactor"
                    }
                  },
                  {
                    "data": {
                      "source": "1607",
                      "target": "1620",
                      "roles": "mutual_interactor-pred"
                    }
                  },
                  {
                    "data": {
                      "source": "1607",
                      "target": "1621",
                      "roles": "mutual_interactor-pred"
                    }
                  },
                  {
                    "data": {
                      "source": "1607",
                      "target": "1623",
                      "roles": "mutual_interactor-seed"
                    }
                  },
                  {
                    "data": {
                      "source": "1607",
                      "target": "1624",
                      "roles": "mutual_interactor-pred"
                    }
                  },
                  {
                    "data": {
                      "source": "1608",
                      "target": "1620",
                      "roles": "mutual_interactor-pred"
                    }
                  },
                  {
                    "data": {
                      "source": "1608",
                      "target": "1621",
                      "roles": "mutual_interactor-pred"
                    }
                  },
                  {
                    "data": {
                      "source": "1608",
                      "target": "1623",
                      "roles": "mutual_interactor-seed"
                    }
                  },
                  {
                    "data": {
                      "source": "1608",
                      "target": "1624",
                      "roles": "mutual_interactor-pred"
                    }
                  },
                  {
                    "data": {
                      "source": "6727",
                      "target": "1663",
                      "roles": "mutual_interactor-seed"
                    }
                  },
                  {
                    "data": {
                      "source": "1620",
                      "target": "2422",
                      "roles": "pred-mutual_interactor"
                    }
                  },
                  {
                    "data": {
                      "source": "1621",
                      "target": "1623",
                      "roles": "pred-seed"
                    }
                  },
                  {
                    "data": {
                      "source": "1624",
                      "target": "4698",
                      "roles": "pred-mutual_interactor"
                    }
                  },
                  {
                    "data": {
                      "source": "3190",
                      "target": "1663",
                      "roles": "mutual_interactor-seed"
                    }
                  }
                ]
              }
            },
            "format": "cyjs",
            "layout": "IPY_MODEL_76cc0692b14e473ab4874f285fa4692e",
            "layout_name": "",
            "visual_style": [
              {
                "selector": "node",
                "css": {
                  "content": "data(genbank)",
                  "border-color": "rgb(256,256,256)",
                  "border-opacity": 1,
                  "border-width": 2
                }
              },
              {
                "selector": "node[role = 'seed']",
                "css": {
                  "background-color": "#f53e37",
                  "width": 20,
                  "height": 20
                }
              },
              {
                "selector": "node[role = 'pred']",
                "css": {
                  "background-color": "#ff9529",
                  "width": 20,
                  "height": 20
                }
              },
              {
                "selector": "node[role = 'mutual_interactor']",
                "css": {
                  "background-color": "#6599d1",
                  "width": 20,
                  "height": 20
                }
              }
            ]
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mutual Interactors\n",
        "Mutual Interactors is a machine learning algorithm for node set expansion in large networks. The algorithm is motivated by the structure of disease-associated proteins, drug targets and protein functions in molecular networks, and can be used to predict molecular phenotypes in silico. For a detailed description of the algorithm, please see our paper.\n",
        "\n",
        "In this notebook, we will walk through how we train a Mutual Interactors model to predict novel disease protein associations. We use a PPI network and a large set of disease-protein associations to train the model.\n",
        "\n",
        "Although this notebook uses a PPI network and disease protein associations, it can easily be retrofitted to work with any network and any node set type."
      ],
      "metadata": {
        "id": "ADStrGThaS2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/seyuboglu/milieu.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "759hEiN0LHmf",
        "outputId": "58a9ad30-2898-4db6-9557-4c56b18d8c3f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'milieu'...\n",
            "remote: Enumerating objects: 4450, done.\u001b[K\n",
            "remote: Counting objects: 100% (1489/1489), done.\u001b[K\n",
            "remote: Compressing objects: 100% (760/760), done.\u001b[K\n",
            "remote: Total 4450 (delta 775), reused 1169 (delta 614), pack-reused 2961 (from 1)\u001b[K\n",
            "Receiving objects: 100% (4450/4450), 182.33 MiB | 12.65 MiB/s, done.\n",
            "Resolving deltas: 100% (2095/2095), done.\n",
            "Updating files: 100% (1142/1142), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd milieu\n",
        "# os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq8etII9LmkE",
        "outputId": "7482707c-1e56-4811-ed01-e283aee7958e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/milieu/milieu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch goatools parse ndex2 cyjupyter\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "from milieu.data.network import Network\n",
        "from milieu.data.associations import load_diseases\n",
        "from milieu.util.util import load_mapping\n",
        "from milieu.milieu import MilieuDataset, Milieu\n",
        "from milieu.paper.figures.network_vis import show_network"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AZbhcN6UMDuS",
        "outputId": "38dc52be-566b-4a1e-936c-3e1b1a87182b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting goatools\n",
            "  Downloading goatools-1.4.12-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting parse\n",
            "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting ndex2\n",
            "  Downloading ndex2-3.10.0-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting cyjupyter\n",
            "  Downloading cyjupyter-0.2.0-py2.py3-none-any.whl.metadata (979 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Collecting docopt (from goatools)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftpretty (from goatools)\n",
            "  Downloading ftpretty-0.4.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from goatools) (1.26.4)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (from goatools) (3.1.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from goatools) (2.2.2)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.11/dist-packages (from goatools) (3.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from goatools) (2.32.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from goatools) (13.9.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from goatools) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from goatools) (75.1.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from goatools) (0.14.4)\n",
            "Collecting xlsxwriter (from goatools)\n",
            "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from ndex2) (1.17.0)\n",
            "Collecting ijson (from ndex2)\n",
            "  Downloading ijson-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from ndex2) (1.0.0)\n",
            "Requirement already satisfied: urllib3>=1.16 in /usr/local/lib/python3.11/dist-packages (from ndex2) (2.3.0)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from cyjupyter) (7.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.0.0->cyjupyter) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.0.0->cyjupyter) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.0.0->cyjupyter) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.0.0->cyjupyter) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.0.0->cyjupyter) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.0.0->cyjupyter) (3.0.13)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from ftpretty->goatools) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl->goatools) (2.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->goatools) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->goatools) (2025.1)\n",
            "Requirement already satisfied: pyparsing>=3.0.9 in /usr/local/lib/python3.11/dist-packages (from pydot->goatools) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->goatools) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->goatools) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->goatools) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->goatools) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->goatools) (2.18.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->goatools) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels->goatools) (24.2)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cyjupyter) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cyjupyter) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cyjupyter) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cyjupyter) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cyjupyter) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cyjupyter) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cyjupyter) (6.4.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets>=7.0.0->cyjupyter)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->cyjupyter) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->cyjupyter) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->cyjupyter) (3.0.50)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->cyjupyter) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->cyjupyter) (4.9.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->goatools) (0.1.2)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.0.0->cyjupyter) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->cyjupyter) (5.7.2)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (1.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.0.0->cyjupyter) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.0.0->cyjupyter) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->cyjupyter) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (3.1.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (25.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (0.23.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cyjupyter) (1.3.1)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading goatools-1.4.12-py3-none-any.whl (15.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
            "Downloading ndex2-3.10.0-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cyjupyter-0.2.0-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftpretty-0.4.0-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading ijson-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.2/119.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=3ace085582944ab9fa6026720dcd534f20e620e76ee245340c89001d0adfdd39\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "Successfully built docopt\n",
            "Installing collected packages: parse, ijson, docopt, xlsxwriter, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, nvidia-cusparse-cu12, nvidia-cudnn-cu12, ftpretty, nvidia-cusolver-cu12, ndex2, goatools, cyjupyter\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed cyjupyter-0.2.0 docopt-0.6.2 ftpretty-0.4.0 goatools-1.4.12 ijson-3.3.0 jedi-0.19.2 ndex2-3.10.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 parse-1.20.2 xlsxwriter-3.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load a Network\n",
        "To use Mutual Interactors we need a network!\n",
        "\n",
        "We'll use the human protein-protein interaction network compiled by Menche et al.[1]. The network consists of 342,353 interactions between 21,557 proteins. Se In data/networks, you can find this network bio-pathways-network.txt. See methods for a more detailed description of the network.\n",
        "\n",
        "We use the class milieu.data.network.Network to load and represent networks. The constructor accepts a path to an edge list."
      ],
      "metadata": {
        "id": "IYMenqUdaM9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Patch the __init__ method for the Network class\n",
        "import os\n",
        "import logging\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "def __patched_init__(self, network_path, remove_edges=0, remove_nodes=0):\n",
        "        \"\"\"\n",
        "        Patched __init__ method for the Network class.\n",
        "        Replaces nx.from_numpy_matrix with nx.from_numpy_array.\n",
        "\n",
        "        Load a protein-proetin interaction network from an adjacency list.\n",
        "        args:\n",
        "            network_path (string)\n",
        "            remove_edges (double) fraction between 0 and 1 inclusive indicating\n",
        "            fraction of edges to randomly remove\n",
        "            remove_nodes (double) fraction between 0 and 1 inclusive indicating\n",
        "            fraction of nodes to randomly remove\n",
        "        \"\"\"\n",
        "        # map protein entrez ids to node index\n",
        "        node_names = set()\n",
        "        edges = []\n",
        "        with open(network_path) as network_file:\n",
        "            for line in network_file:\n",
        "                if remove_edges > 0 and random.random() < remove_edges:\n",
        "                    continue\n",
        "                p1, p2 = [int(a) for a in line.split()]\n",
        "                node_names.add(p1)\n",
        "                node_names.add(p2)\n",
        "                edges.append((p1, p2))\n",
        "        if remove_nodes > 0:\n",
        "            assert(remove_nodes < 1)\n",
        "            node_names = random.sample(node_names, 1 - remove_nodes)\n",
        "\n",
        "        self.name_to_node = {p: n for n, p in enumerate(node_names)}\n",
        "        self.node_to_name = {n: p for p, n in self.name_to_node.items()}\n",
        "\n",
        "        # build adjacency matrix\n",
        "        self.adj_matrix = np.zeros((len(self.name_to_node),\n",
        "                                    len(self.name_to_node)))\n",
        "        for p1, p2 in edges:\n",
        "            n1, n2 = self.name_to_node[p1], self.name_to_node[p2]\n",
        "            self.adj_matrix[n1, n2] = 1\n",
        "            self.adj_matrix[n2, n1] = 1\n",
        "\n",
        "        # self.nx = nx.from_numpy_matrix(self.adj_matrix)\n",
        "        self.nx = nx.from_numpy_array(self.adj_matrix)\n",
        "\n",
        "\n",
        "# Apply the patch\n",
        "Network.__init__ = __patched_init__\n",
        "\n",
        "# Now you can use the Network class as before\n",
        "network = Network(\"data/networks/species_9606/bio-pathways/network.txt\")"
      ],
      "metadata": {
        "id": "QVKUVHJdO77h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Milieu Model\n",
        "The Mutual Interactors is parameterized by a few important hyperparameters.\n",
        "\n",
        "We find that learning rate parameter (i.e. optim_args/lr in the nested dictionary below) can have significant impact on performance. The optimal value varies substantially between networks and applications, so we recommend tuning it.\n",
        "\n",
        "If you have a GPU available, setting cuda to True and specifying an available device should speed up training considerably. That being said, training Mutual Interactors is usually tractable on CPU for networks with\n",
        "."
      ],
      "metadata": {
        "id": "NGcUiugGaGZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Patch the build_model method for the Milieu class\n",
        "# import os\n",
        "import json\n",
        "import logging\n",
        "from shutil import copyfile\n",
        "from collections import defaultdict\n",
        "from copy import deepcopy\n",
        "\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from scipy.sparse import coo_matrix, csr_matrix\n",
        "import parse\n",
        "\n",
        "from milieu.paper.methods.method import DPPMethod\n",
        "from milieu.data.associations import load_node_sets\n",
        "from milieu.util.metrics import compute_metrics\n",
        "from milieu.util.util import set_logger, load_mapping\n",
        "\n",
        "def _patched_build_model(self):\n",
        "        \"\"\"\n",
        "        Initialize the variables and parameters of the Milieu model.\n",
        "        See Methods, Equation (2) for corresponding mathematical definition.\n",
        "        \"\"\"\n",
        "        # degree vector, (D^{-0.5} in Equation (2))\n",
        "        degree = np.sum(self.adj_matrix, axis=1, dtype=float)\n",
        "        inv_sqrt_degree = np.power(degree, -0.5)\n",
        "        inv_sqrt_degree = torch.tensor(inv_sqrt_degree, dtype=torch.float)\n",
        "\n",
        "        # adjacency matrix of network, (A in Equation (2))\n",
        "        adj_matrix = torch.tensor(self.adj_matrix, dtype=torch.float)\n",
        "\n",
        "        # precompute the symmetric normalized adj matrix, used on the left of Equation (2)\n",
        "        adj_matrix_left = torch.mul(torch.mul(inv_sqrt_degree.view(1, -1),\n",
        "                                              adj_matrix),\n",
        "                                    inv_sqrt_degree.view(-1, 1))\n",
        "\n",
        "        # precompute the normalized adj matrix, used on the right of Equation (2)\n",
        "        adj_matrix_right = torch.mul(inv_sqrt_degree.view(1, -1),\n",
        "                                     adj_matrix)\n",
        "        self.register_buffer(\"adj_matrix_right\", adj_matrix_right)\n",
        "        self.register_buffer(\"adj_matrix_left\", adj_matrix_left)\n",
        "\n",
        "        # milieu weight vector, ('W' in Equation (2))\n",
        "        self.milieu_weights = nn.Parameter(torch.ones(1, 1, adj_matrix.shape[0],\n",
        "                                           dtype=torch.float,\n",
        "                                           requires_grad=True))\n",
        "\n",
        "        # scaling parameter, ('a' in in Equation (2))\n",
        "        self.scale = nn.Linear(1, 1)\n",
        "\n",
        "        # the bias parameter, ('b' in Equation (2))\n",
        "        self.bias = nn.Parameter(torch.ones(size=(1,),\n",
        "                                            dtype=torch.float,\n",
        "                                            requires_grad=True))\n",
        "\n",
        "\n",
        "# Apply the patch\n",
        "Milieu._build_model = _patched_build_model"
      ],
      "metadata": {
        "id": "r3pIXfX8QsCU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"cuda\": False,\n",
        "    \"device\": 2,\n",
        "\n",
        "    \"batch_size\": 200,\n",
        "    \"num_workers\": 4,\n",
        "    \"num_epochs\": 10,\n",
        "\n",
        "    \"optim_class\": \"Adam\",\n",
        "    \"optim_args\": {\n",
        "        \"lr\": 0.01,\n",
        "        \"weight_decay\": 0.0\n",
        "    },\n",
        "\n",
        "    \"metric_configs\": [\n",
        "        {\n",
        "            \"name\": \"recall_at_25\",\n",
        "            \"fn\": \"batch_recall_at\",\n",
        "            \"args\": {\"k\":25}\n",
        "        }\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "StmDeRejNQ0g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've implemented the Mutual Interactors model in a self-contained class milieu.milieu.Milieu. This class contains methods for training the model Milieu.train_model, evaluating the model on a test set Milieu.score and predicting node set expansions Milieu.expand.\n",
        "\n",
        "The constructor accepts the network and the dictionary of params we defined above."
      ],
      "metadata": {
        "id": "IPpJ2CTOZ-nc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "milieu = Milieu(network, params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgmTgLqYQWph",
        "outputId": "bf29400e-3c09-4c0a-8059-6db68598445b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Milieu\n",
            "INFO:root:Setting parameters...\n",
            "INFO:root:Building model...\n",
            "INFO:root:Building optimizer...\n",
            "INFO:root:Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model\n",
        "Mutual Interactors is trained on a dataset of groups of nodes known to be associated with one another in some way.\n",
        "In this example, we use sets of proteins associated with the same disease. Our disease-protein associations come from disgenet and are found at data/disease_associations/disgenet-associations.csv.\n",
        "\n",
        "We load the disease-protein associations with milieu.data.associations.load_diseases which returns a list of milieu.data.associations.NodeSet. Each NodeSet represents the set of proteins associated with on disease.\n",
        "\n",
        "To evaluate the model as we train it, we'll split the set of diseases into train set and a validation set. Next, we'll create a milieu.milieu.MilieuDataset for each. A MilieuDataset is simply a PyTorch dataset that creates training examples for the Mutual Interactors momdel."
      ],
      "metadata": {
        "id": "G5dEwk7yZ3qS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_sets = list(load_diseases(\"data/associations/disgenet/associations.csv\", exclude_splits=[\"none\"]).values())\n",
        "train_node_sets = node_sets[:int(len(node_sets)* 0.9)]\n",
        "valid_node_sets = node_sets[int(len(node_sets)* 0.9):]\n",
        "train_dataset = MilieuDataset(network, node_sets=train_node_sets)\n",
        "valid_dataset = MilieuDataset(network, node_sets=valid_node_sets)"
      ],
      "metadata": {
        "id": "u_lVPqXcQX7n"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "milieu.train_model(train_dataset, valid_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2xswDHPWtoJ",
        "outputId": "dc14cf04-ce9e-4c55-8351-be2f53ec5112"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Starting training for 10 epoch(s)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "INFO:root:Epoch 1 of 10\n",
            "INFO:root:Training\n",
            "100%|██████████| 9/9 [00:58<00:00,  6.48s/it, loss=1.405]\n",
            "INFO:root:Validation\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [00:06<00:00,  6.13s/it]\n",
            "INFO:root:Epoch 2 of 10\n",
            "INFO:root:Training\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 9/9 [00:58<00:00,  6.55s/it, loss=1.386]\n",
            "INFO:root:Validation\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [00:06<00:00,  6.04s/it]\n",
            "INFO:root:Epoch 3 of 10\n",
            "INFO:root:Training\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 9/9 [00:58<00:00,  6.45s/it, loss=1.379]\n",
            "INFO:root:Validation\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [00:06<00:00,  6.00s/it]\n",
            "INFO:root:Epoch 4 of 10\n",
            "INFO:root:Training\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 9/9 [01:00<00:00,  6.69s/it, loss=1.374]\n",
            "INFO:root:Validation\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [00:05<00:00,  5.97s/it]\n",
            "INFO:root:Epoch 5 of 10\n",
            "INFO:root:Training\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 9/9 [01:00<00:00,  6.76s/it, loss=1.367]\n",
            "INFO:root:Validation\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [00:05<00:00,  5.29s/it]\n",
            "INFO:root:Epoch 6 of 10\n",
            "INFO:root:Training\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 9/9 [00:59<00:00,  6.59s/it, loss=1.360]\n",
            "INFO:root:Validation\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [00:06<00:00,  6.02s/it]\n",
            "INFO:root:Epoch 7 of 10\n",
            "INFO:root:Training\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 9/9 [00:58<00:00,  6.47s/it, loss=1.352]\n",
            "INFO:root:Validation\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [00:06<00:00,  6.40s/it]\n",
            "INFO:root:Epoch 8 of 10\n",
            "INFO:root:Training\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 9/9 [00:59<00:00,  6.59s/it, loss=1.345]\n",
            "INFO:root:Validation\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [00:06<00:00,  6.17s/it]\n",
            "INFO:root:Epoch 9 of 10\n",
            "INFO:root:Training\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 9/9 [00:59<00:00,  6.61s/it, loss=1.332]\n",
            "INFO:root:Validation\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [00:05<00:00,  5.61s/it]\n",
            "INFO:root:Epoch 10 of 10\n",
            "INFO:root:Training\n",
            "  0%|          | 0/9 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 9/9 [01:00<00:00,  6.69s/it, loss=1.326]\n",
            "INFO:root:Validation\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [00:05<00:00,  5.82s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([{'recall_at_25': 0.006091663764077557},\n",
              "  {'recall_at_25': 0.059985388050820466},\n",
              "  {'recall_at_25': 0.06066606852165254},\n",
              "  {'recall_at_25': 0.06508019929380804},\n",
              "  {'recall_at_25': 0.05829975091137153},\n",
              "  {'recall_at_25': 0.06253906905967097},\n",
              "  {'recall_at_25': 0.0612237380727925},\n",
              "  {'recall_at_25': 0.07128082395445749},\n",
              "  {'recall_at_25': 0.07040908104168589},\n",
              "  {'recall_at_25': 0.0709470499921994}],\n",
              " [defaultdict(list, {'recall_at_25': [0.04710632773819586]}),\n",
              "  defaultdict(list, {'recall_at_25': [0.056331763474620614]}),\n",
              "  defaultdict(list, {'recall_at_25': [0.06323854368967151]}),\n",
              "  defaultdict(list, {'recall_at_25': [0.030811247157401005]}),\n",
              "  defaultdict(list, {'recall_at_25': [0.06288809031724012]}),\n",
              "  defaultdict(list, {'recall_at_25': [0.048472360972360976]}),\n",
              "  defaultdict(list, {'recall_at_25': [0.055701502404799104]}),\n",
              "  defaultdict(list, {'recall_at_25': [0.05781070433326072]}),\n",
              "  defaultdict(list, {'recall_at_25': [0.06087483596882092]}),\n",
              "  defaultdict(list, {'recall_at_25': [0.06776840536239032]})])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predict Novel Associations\n",
        "Now that we've got a trained Mutual Interactors model, we can use it to expand some node sets!\n",
        "\n",
        "In particular, here we are going to use it to predict which proetins are associated with Tracheomalacia, a condition characterized by flaccidity of the supporting tracheal cartilage.\n",
        "\n",
        "To do so, we specify the set of proteins associated with Tracheomalacia using GenBank IDs."
      ],
      "metadata": {
        "id": "GO8U2m3Ibza6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify a set of proteins by their GenBank IDs\n",
        "# For example, we use the proteins associated with Tracheomalacia\n",
        "# Swap out these GenBank IDs for another set of proteins!\n",
        "tracheomalacia_proteins = ['COL2A1', 'HRAS', 'DCHS1', 'SNRPB', 'ORC4', 'LTBP4',\n",
        "                           'FLNB', 'PRRX1', 'RAB3GAP2', 'FGFR2','TRIM2']"
      ],
      "metadata": {
        "id": "2673vqy5WwHS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert genbank ids to entrez ids, since our network uses entrez ids\n",
        "genbank_to_entrez = load_mapping(\"data/protein_attrs/genbank_to_entrez.txt\",\n",
        "                                 b_transform=int, delimiter='\\t')\n",
        "tracheomalacia_entrez = [genbank_to_entrez[protein] for protein in tracheomalacia_proteins]"
      ],
      "metadata": {
        "id": "_U2xoFWeb6I3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand the set of proteins using our trained model!\n",
        "# Change the number of predicted proteins using the top_k parameter\n",
        "predicted_entrez = milieu.expand(node_names=tracheomalacia_entrez, top_k=5)\n",
        "predicted_entrez = list(zip(*predicted_entrez))[0]"
      ],
      "metadata": {
        "id": "989HQdYCb86t"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the function milieu.paper.figures.network_vis.show_network we can generate a Cytoscape visualization of the predictions!"
      ],
      "metadata": {
        "id": "xwB4wBkvb9k5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "gLHiQu04gpL9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Patch the show_network and get_network functiosn in milieu.paper.figures.network_vis\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "\n",
        "import ndex2.client as nc\n",
        "from cyjupyter import Cytoscape\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "from milieu.util.util import load_mapping\n",
        "from milieu.util.util import ensure_dir_exists\n",
        "\n",
        "def patched_show_network(network, seed_proteins, pred_proteins,\n",
        "                 id_format=\"genbank\", style=None, show_seed_mi=True,\n",
        "                 model=None, excluded_interactions=[], save_path=None,\n",
        "                 size_limit=200):\n",
        "    \"\"\"\n",
        "    Generate a cytoscape jupyter visualization for the induced subgraph of seed_proteins,\n",
        "    pred_proteins and the mutual interactors between them.\n",
        "    \"\"\"\n",
        "    if id_format == \"genbank\":\n",
        "        genbank_to_entrez = load_mapping(\"data/protein_attrs/genbank_to_entrez.txt\",\n",
        "                                         b_transform=int, delimiter='\\t')\n",
        "        seed_proteins = [genbank_to_entrez[protein]\n",
        "                         for protein in seed_proteins if protein in genbank_to_entrez]\n",
        "        pred_proteins = [genbank_to_entrez[protein]\n",
        "                         for protein in pred_proteins if protein in genbank_to_entrez]\n",
        "        seed_nodes = network.get_nodes(seed_proteins)\n",
        "        pred_nodes = network.get_nodes(pred_proteins)\n",
        "\n",
        "    elif id_format == \"entrez\":\n",
        "        seed_nodes = network.get_nodes(seed_proteins)\n",
        "        pred_nodes = network.get_nodes(pred_proteins)\n",
        "    else:\n",
        "        raise ValueError(\"id_format is not recognized.\")\n",
        "\n",
        "    cyjs_network = patched_get_network(network, seed_nodes, pred_nodes, model,\n",
        "                               show_seed_mi, excluded_interactions, size_limit)\n",
        "    # Unique ID for a network entry in NDEx\n",
        "    uuid = 'f28356ce-362d-11e5-8ac5-06603eb7f303'\n",
        "\n",
        "    # NDEx public server URL\n",
        "    ndex_url = 'http://public.ndexbio.org/'\n",
        "\n",
        "    # Create an instance of NDEx client\n",
        "    #ndex = nc.Ndex2(ndex_url)\n",
        "\n",
        "    # Download the network in CX format\n",
        "    #response = ndex.get_network_as_cx_stream(uuid)\n",
        "\n",
        "    # Store the data in a Python object\n",
        "    #cx = response.json()\n",
        "\n",
        "    if style is None:\n",
        "        style = [\n",
        "            {\n",
        "                \"selector\": \"node\",\n",
        "                \"css\": {\n",
        "                    \"content\": \"data(genbank)\",\n",
        "                    \"border-color\" : \"rgb(256,256,256)\",\n",
        "                    \"border-opacity\" : 1.0,\n",
        "                    \"border-width\" : 2,\n",
        "\n",
        "                },\n",
        "            },\n",
        "            {\n",
        "                \"selector\": \"node[role = 'seed']\",\n",
        "                \"css\": {\n",
        "                    \"background-color\": \"#f53e37\",\n",
        "                    \"width\": 20,\n",
        "                    \"height\": 20\n",
        "                },\n",
        "            },\n",
        "            {\n",
        "                \"selector\": \"node[role = 'pred']\",\n",
        "                \"css\": {\n",
        "                    \"background-color\": \"#ff9529\",\n",
        "                    \"width\": 20,\n",
        "                    \"height\": 20\n",
        "                },\n",
        "            },\n",
        "            {\n",
        "                \"selector\": \"node[role = 'mutual_interactor']\",\n",
        "                \"css\": {\n",
        "                    \"background-color\": \"#6599d1\",\n",
        "                    \"width\": 20,\n",
        "                    \"height\": 20\n",
        "                },\n",
        "            }\n",
        "        ]\n",
        "\n",
        "    if save_path is not None:\n",
        "        with open(save_path, 'w') as f:\n",
        "            json.dump(cyjs_network, f, indent=4)\n",
        "\n",
        "    cytoscape = Cytoscape(data=cyjs_network, visual_style=style)\n",
        "    return cytoscape\n",
        "\n",
        "def patched_get_network(network, seed_nodes, pred_nodes, model=None,\n",
        "                show_seed_mi=True, excluded_interactions=[], size_limit=200):\n",
        "    \"\"\" Get the disease subgraph of\n",
        "    Args:\n",
        "        disease: (Disease) A disease object\n",
        "    \"\"\"\n",
        "    entrez_to_genbank = load_mapping(\"data/protein_attrs/genbank_to_entrez.txt\",\n",
        "                                     b_transform=int, delimiter='\\t', reverse=True)\n",
        "    nodes = {}\n",
        "\n",
        "    def add_node(node, role=\"seed\"):\n",
        "        if node not in nodes:\n",
        "            if model is not None and role == \"mutual_interactor\":\n",
        "                weight = float(model.milieu_weights[0, 0, node] / np.sqrt(network.nx.degree(node)))\n",
        "            else:\n",
        "                weight = 1.0\n",
        "            nodes[node] = {\n",
        "                \"data\": {\n",
        "                    \"role\": role,\n",
        "                    \"id\": str(node),\n",
        "                    \"entrez\": str(network.get_name(node)),\n",
        "                    \"genbank\": entrez_to_genbank.get(network.get_name(node), \"\"),\n",
        "                    \"normalized_milieu_weight\": weight\n",
        "                }\n",
        "            }\n",
        "\n",
        "    # add seed nodes\n",
        "    for seed_node in seed_nodes:\n",
        "        add_node(seed_node, role=\"seed\")\n",
        "\n",
        "    # get seed node neighbors\n",
        "    seed_node_to_nbrs = {node: set(network.nx.neighbors(node))\n",
        "                         for node in seed_nodes}\n",
        "    # get mutual interactors between preds and seed\n",
        "    for pred_node in pred_nodes:\n",
        "        add_node(pred_node, role=\"pred\")\n",
        "    for pred_node in pred_nodes:\n",
        "        pred_nbrs = set(network.nx.neighbors(pred_node))\n",
        "        for seed_node in seed_nodes:\n",
        "            seed_nbrs = seed_node_to_nbrs[seed_node]\n",
        "            common_nbrs = seed_nbrs & pred_nbrs\n",
        "            for common_nbr in common_nbrs:\n",
        "                add_node(common_nbr, role=\"mutual_interactor\")\n",
        "\n",
        "    # the set of nodes intermediate between nodes in the\n",
        "    if show_seed_mi:\n",
        "        for a, node_a in enumerate(seed_nodes):\n",
        "            for b, node_b in enumerate(seed_nodes):\n",
        "                # avoid repeat pairs\n",
        "                if a >= b:\n",
        "                    continue\n",
        "                common_nbrs = seed_node_to_nbrs[node_a] & seed_node_to_nbrs[node_b]\n",
        "                for common_nbr in common_nbrs:\n",
        "                    add_node(common_nbr, role=\"mutual_interactor\")\n",
        "\n",
        "    if size_limit is not None:\n",
        "        if size_limit < len(seed_nodes) + len(pred_nodes):\n",
        "            raise ValueError(f\"size_limit ({size_limit}) must be at least as large as the total number\" +\n",
        "                             f\"of seed and predicted nodes ({len(seed_nodes) + len(pred_nodes)}).\")\n",
        "        while len(nodes) > size_limit:\n",
        "            node = random.choice(list(nodes.keys()))\n",
        "            node_data = nodes[node][\"data\"]\n",
        "            if node_data[\"role\"] == \"mutual_interactor\":\n",
        "                del nodes[node]\n",
        "\n",
        "    # get induced subgraph\n",
        "    subgraph = nx.Graph(network.nx.subgraph(nodes.keys()))\n",
        "\n",
        "    # subgraph.remove_edges_from(subgraph.selfloop_edges())\n",
        "    subgraph.remove_edges_from(list(nx.selfloop_edges(subgraph)))  # Use nx.selfloop_edges to get self-loop edges\n",
        "\n",
        "    edges = []\n",
        "    for edge in subgraph.edges():\n",
        "        if (nodes[edge[0]][\"data\"][\"role\"],\n",
        "            nodes[edge[1]][\"data\"][\"role\"]) in excluded_interactions:\n",
        "            continue\n",
        "        edges.append({\n",
        "            \"data\": {\n",
        "                \"source\": str(edge[0]),\n",
        "                \"target\": str(edge[1]),\n",
        "                \"roles\": f'{nodes[edge[0]][\"data\"][\"role\"]}-{nodes[edge[1]][\"data\"][\"role\"]}'\n",
        "            }\n",
        "        })\n",
        "\n",
        "    return {\"elements\": {\"nodes\": list(nodes.values()), \"edges\": edges}}"
      ],
      "metadata": {
        "id": "Gg_uiMtOfISy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a network visualization with cytoscape\n",
        "# Note: it is recommended to limit the size of the visualization to ~250 nodes\n",
        "cy_vis = patched_show_network(network, tracheomalacia_entrez, predicted_entrez, id_format=\"entrez\",\n",
        "                      model=milieu,\n",
        "                      show_seed_mi=True, excluded_interactions=[(\"mutual_interactor\", \"mutual_interactor\")],\n",
        "                      size_limit=250)"
      ],
      "metadata": {
        "id": "SQ0gct_6cCgJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the visualization!\n",
        "# Red nodes are the seed nodes fed to the momdel.\n",
        "# Orange nodes are predicted nodes. Blue nodes are the interactors between them.\n",
        "cy_vis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "96d6acc3170d41c8bc95dd97e480ddba"
          ]
        },
        "id": "INMn0YpHcH4b",
        "outputId": "297b982f-9581-4ee8-b071-ae5bba9f7293"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Cytoscape(data={'elements': {'nodes': [{'data': {'role': 'seed', 'id': '925', 'entrez': '1280', 'genbank': 'CO…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96d6acc3170d41c8bc95dd97e480ddba"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Milieu model for C. elegans"
      ],
      "metadata": {
        "id": "vibvId4Y08TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "network = Network(\"data/networks/species_9606/bio-pathways/network.txt\")"
      ],
      "metadata": {
        "id": "tmrjl-As2vmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Patch the __init__ method for the Network class\n",
        "import os\n",
        "import logging\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "class PULoss(nn.Module):\n",
        "    def __init__(self, positive_weight=1.0, unlabeled_weight=0.1):\n",
        "        \"\"\"\n",
        "        PU Learning loss function for Mutual Interactors model.\n",
        "\n",
        "        Args:\n",
        "        - positive_weight (float): Weight for known positives.\n",
        "        - unlabeled_weight (float): Initial weight for unlabeled nodes.\n",
        "        \"\"\"\n",
        "        super(PULoss, self).__init__()\n",
        "        self.positive_weight = positive_weight\n",
        "        self.unlabeled_weight = unlabeled_weight\n",
        "\n",
        "    def forward(self, outputs, labels, unlabeled_mask):\n",
        "        \"\"\"\n",
        "        Compute PU learning loss.\n",
        "\n",
        "        Args:\n",
        "        - outputs (Tensor): Model probability outputs (logits).\n",
        "        - labels (Tensor): Binary tensor (1 for positive nodes, 0 for others).\n",
        "        - unlabeled_mask (Tensor): Binary tensor (1 for unlabeled nodes, 0 for positives).\n",
        "\n",
        "        Returns:\n",
        "        - loss (Tensor): Weighted binary cross-entropy loss.\n",
        "        \"\"\"\n",
        "        pos_loss = -self.positive_weight * labels * torch.log(torch.sigmoid(outputs) + 1e-8)\n",
        "        w_j = self.unlabeled_weight  # Can be refined dynamically\n",
        "        unlabeled_loss = -w_j * unlabeled_mask * torch.log(1 - torch.sigmoid(outputs) + 1e-8)\n",
        "\n",
        "        loss = pos_loss + unlabeled_loss\n",
        "        return loss.mean()\n",
        "\n",
        "class MilieuWorm(nn.Module):\n",
        "    def __init__(self, ...):\n",
        "        super(Milieu, self).__init__()\n",
        "        self.loss_fn = PULoss(positive_weight=1.0, unlabeled_weight=0.5)  # Replace BCE loss\n",
        "\n",
        "    def loss(self, outputs, targets, unlabeled_mask):\n",
        "        return self.loss_fn(outputs, targets, unlabeled_mask)\n",
        "\n",
        "    # def _build_model(self):\n",
        "    #     \"\"\"\n",
        "    #     Initialize the variables and parameters of the Milieu model.\n",
        "    #     See Methods, Equation (2) for corresponding mathematical definition.\n",
        "    #     \"\"\"\n",
        "    #     # degree vector, (D^{-0.5} in Equation (2))\n",
        "    #     degree = np.sum(self.adj_matrix, axis=1, dtype=float)\n",
        "    #     inv_sqrt_degree = np.power(degree, -0.5)\n",
        "    #     inv_sqrt_degree = torch.tensor(inv_sqrt_degree, dtype=torch.float)\n",
        "\n",
        "    #     # adjacency matrix of network, (A in Equation (2))\n",
        "    #     adj_matrix = torch.tensor(self.adj_matrix, dtype=torch.float)\n",
        "\n",
        "    #     # precompute the symmetric normalized adj matrix, used on the left of Equation (2)\n",
        "    #     adj_matrix_left = torch.mul(torch.mul(inv_sqrt_degree.view(1, -1),\n",
        "    #                                           adj_matrix),\n",
        "    #                                 inv_sqrt_degree.view(-1, 1))\n",
        "\n",
        "    #     # precompute the normalized adj matrix, used on the right of Equation (2)\n",
        "    #     adj_matrix_right = torch.mul(inv_sqrt_degree.view(1, -1),\n",
        "    #                                  adj_matrix)\n",
        "    #     self.register_buffer(\"adj_matrix_right\", adj_matrix_right)\n",
        "    #     self.register_buffer(\"adj_matrix_left\", adj_matrix_left)\n",
        "\n",
        "    #     # milieu weight vector, ('W' in Equation (2))\n",
        "    #     self.milieu_weights = nn.Parameter(torch.ones(1, 1, adj_matrix.shape[0],\n",
        "    #                                        dtype=torch.float,\n",
        "    #                                        requires_grad=True))\n",
        "\n",
        "    #     # scaling parameter, ('a' in in Equation (2))\n",
        "    #     self.scale = nn.Linear(1, 1)\n",
        "\n",
        "    #     # the bias parameter, ('b' in Equation (2))\n",
        "    #     self.bias = nn.Parameter(torch.ones(size=(1,),\n",
        "    #                                         dtype=torch.float,\n",
        "    #                                         requires_grad=True))\n",
        "\n"
      ],
      "metadata": {
        "id": "wkNFwN3J08zN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}